---
title: "TRIP GENERATION"
output: html_document
---

Will be replaced by an autodoc eventually

This script estimates block-level trips by household type and non-home 
attractions.  This is accomplished in 5 major steps:
    
  1. Estimate activity-based block trip gen propensity by purpose
      - Propensities are estimated such that every block has an extremely small starting propensity, and this grows based on block activities. This is to alleviate potential discontinuities between block-level and TAZ-level activity estimates.
      - Production propensity is informed by HH types
      - Attraction propensity is informed by job types and enrollments
        
  2. Summarize total block trip-making propensity by purpose
      - Summarize the activity-based propensities to yield the total trip-making propensity for the block.The resulting score is the total trip gen propensity (either for P's or A's) by purpose.
      - Summarize the block-level totals to TAZs. This will be used to determine each block's share of total trip-making propensity.
          
  3. Normalize the activity-based propensities such that they sum to 1.0 within each block.
      - When each block's trip total is estimated, these shares will determine trips by activity type.
    
  4. Summarize block-level total trip propensity to TAZ and estimate block-level shares of TAZ totals (by purpose and trip-end) by activity.
        
  5. Multiply TAZ-level trip estimates by purpose and trip-end to block-level, activity-based normalized propensities. This yields activity-based trips by block.


# {.tabset}

## STEP 1

### IMPORTS
```{python eval = FALSE}
import sys
sys.path.append(r"K:\Tools\RP\emma\scripts")

import emma
from emma import ipf
from emma import labeled_array as lba
import pandas as pd
import numpy as np
import os

root = r"K:\Projects\MAPC\WestStationScenarios"
os.chdir(root)
lu_config = "FEIR_MAX"
```

### GLOBAL AND ASSUMPTIONS
        
```{python eval = FALSE}
PURPOSES = ["HBW", "HBO", "HBSch", "NHB"]
HB_PURPS = [p for p in PURPOSES if p!= "NHB"]

# Generalized trip-making propensity assumptions are used to guide the
#  trip gen disaggregation process. Trip totals are governed by the regional
#  TAZ-level estimates, but these are pushed down to blocks based on the
#  block-level activities and their relative trip-making propensities.
#  Define the trip making propensities below. 

BASE_PROP = 0.0001

# HH Size: as household size increases, trip-making increases (there are 4
#          size classes -  1 person, 2 persons, 3 persons, 4+ persons)
HHSIZE_PROP = [10, 20, 30, 35]

# Income: as income increases, trip-making increases (there are 4 income 
#         classes - less than $35k, $35-75K, $75-125K, $125K+)
INCOME_PROP = [10, 20, 30, 40]

# Workers: as the number of workers increases, trip-making increases (there
#          are 4 worker classes - no workers, 1 worker, 2 workers, 3+ workers)
WORKER_PROP = [5, 10, 20, 30]

# Vehicle Ownership: as the number of vehicles increases, trip-making 
#                    goes up slightly (there are 4 vehicle ownership classes - 
#                    no vehicles, 1 vehicle, 2 vehicles, 3+ vehicles)
VEHICLE_PROP = [10, 15, 20, 20]

# Attraction-end activities: different attraction end activities impact
#  trip-making differently by purpose. 
ATTR_ACTIVITIES = ["Basic", "Retail", "Service", "EnrollPreK", "EnrollK12",
                   "EnrollCU"]

# Each activity's purpose-specific propensity is stored in a dictionary.
#  Propensity values are listed in the order shown in the list above to 
#  make a nested dictionary.
ATTR_PROP = {
    "HBW": dict(zip(ATTR_ACTIVITIES, [40, 40, 40, 1, 1, 1])),
    "HBO": dict(zip(ATTR_ACTIVITIES, [5, 40, 20, 1, 1, 1])),
    "HBSch": dict(zip(ATTR_ACTIVITIES, [1, 1, 1, 10, 30, 40])),
    "NHB": dict(zip(ATTR_ACTIVITIES, [40, 40, 40, 10, 10, 20]))
    }
```
        
### READ AND PROCESS INPUT DATA
```{python eval = FALSE}
#%% READ INPUT DATA
# For trip disaggregation, we need the following data sets
#  - Block level activity data
#     - Households by type
#     - Jobs by type and school enrollments
#  - A lookup table of blocks-to-TAZs and which blocks are in the window and
#     focus areas
#  - TAZ-level trip generation estimates

# Block level activity
#  - Households by type
hh_file = r"input\Zones\{}\Household_Types_by_Block.csv".format(lu_config)
hh_df = pd.read_csv(hh_file, dtype={"block_id": str})

#  - Jobs by type and enrollments
nh_file = r"input\Zones\{}\Jobs_Enroll_by_Block.csv".format(lu_config)
nh_df = pd.read_csv(nh_file, dtype={"block_id": str})

# Block lookup data
window_blocks_file = r"input\window_blocks.csv"
wb_df = pd.read_csv(window_blocks_file, dtype={"GEOID10": str})

# TAZ-level trip generation estimates
#  These are stored in a mulit-dimensional array by activity type
taz_tg_file = r"lu\{}\trips_by_taz.h5".format(lu_config)
taz_tg = lba.openLbArray_HDF(taz_tg_file, "/trips")

#%% PROCESS INPUT DATA

# Create a labeled array of households by type in the window area.

# Disaggregation only needs to occur for locations in the window area.
#  Use the block lookup data to get the TAZ's in the window area and 
#  the focus area.
window_zones = wb_df[wb_df["INWINDOW"] == 1]["TAZ"].unique()
focus_zones = wb_df[wb_df["INFOCUS"] == 1]["TAZ"].unique()

# Convert block-level household details into a labeled array for the window
#  area. Ensure dimensioning matches the TAZ trip gen dimensions.
hh_dims = ["HHSize", "Income", "Workers", "VehOwn"]
dim_cols = ["block_id"] + [x_name for x_name in taz_tg.axisNames() if 
                           x_name in hh_dims]

# Left join block HH data to the window blocks file to ensure all blocks in
#  in the window are included. For gaps in the households data, use dummy
#  values (zero households, e.g.). This helps ensure consistent dimensionsing 
#  of activity and trip arrays across LU configurations.

# Dummy values for HH dimension labels are tiled based on the values expected
#  to be present to ensure that all household types are represented in the
#  resulting array.
hh_df = wb_df.merge(hh_df, how="left", left_on="GEOID10", right_on="block_id")
hh_df.Households.fillna(0, inplace=True)

for dim in hh_dims:
    # Lookup axis labels and "tile" them as fill values - missing records
    #  will be populated with each HH dimension label in series.
    ref_axis = taz_tg.getAxisByName(dim)
    fill_vals = [label for label in ref_axis.labels if label != "-"]

    
    # Make a copy of the dimension columns and a mask array of missing values
    #  (tally the number of na's)
    col_vals = hh_df[dim].values
    mask = pd.isna(hh_df[dim]).values
    num_na = len(col_vals[mask])
    fill_series = np.tile(fill_vals, (num_na//len(fill_vals)) + 1)

    # Fill column values with tiled labels and update the data frame
    col_vals[mask] = fill_series[:num_na]
    hh_df[dim] = pd.Series(col_vals)

# Convert the hh data frame to a labeled array
hh_df["block_id"] = hh_df["GEOID10"]
hh_array = lba.dfToLabeledArray(hh_df.sort_values(by="block_id"), 
                                dim_cols, "Households", fill_value=0.0)

# Add the parent TAZ ID as a new level in the `block_id` axis.
#  Then update the level names so `index` is replaced with `block_id`
hh_array.block_id.addLevel(
    wb_df[["GEOID10", "TAZ"]], left_on="index", right_on="GEOID10")
hh_array.block_id.levels = ["block_id", "TAZ"]
```

### Setting Output Container
```{python eval = FALSE}
# Write two new H5 files to hold block-level data
#  - Save the households by type data to an on-disk labeled array
#  - Create a new on-disk labeled array to store block-level trip estimates

# HHs by type
hdf_store = r"lu\{}\HHs_by_type_block.h5".format(lu_config)
node_path = "/"
name = "households"
# Use the `copy` method to store it on disk
hh_output = hh_array.copy(hdf_store, node_path, name)

# Trip container
#  The array for block-level trip data has the same organization and 
#  dimensions as the trip array for TAZs, except the TAZ `dimension` is
#  replaced with a `block_id` dimension.
hdf_store = r"lu\{}\trips_by_block.h5".format(lu_config)
node_path = "/"
name = "trips"
# Create an impression to set dimensions
block_imp = taz_tg.cast(hh_array.block_id, copy_data=False, drop="TAZ")
# Fill the impression to initialize all values to zero on-disk
block_tg = block_imp.fill(0.0, hdf_store, node_path, name)

```

## STEP 2

### APPLYING TRIP PROPENSITIES
```{python eval = FALSE}
# Apply trip propensities by household dimensions to each block.
#  This is done by broadcasting the propensity values to match the
#  dimensions of `hh_array` and updating the data through multiplication

hh_props = [HHSIZE_PROP, INCOME_PROP, WORKER_PROP, VEHICLE_PROP]
for dim, prop_rates in zip(hh_dims, hh_props):
    hh_array.data *= lba.broadcast1dByAxis(hh_array, dim, prop_rates).data

# Bump each propensity value up by the `BASE_PROP` constant
hh_array.data += BASE_PROP
```

## STEP 3

### SUMMARIZING TRIP PROPENSITIES
```{python eval = FALSE}
# Summarize each block's total trip propensity using the .sum method.
block_prop_hh = hh_array.sum("block_id")

# Dissolve the block-level sums based on TAZ ID to get each zone's total
#  propensity
taz_prop_hh = hh_array.dissolve("block_id", "TAZ", np.sum).sum("block_id")
```

## STEP 4

### BLOCK SHARE OF TAZ TRIP PROPENSITY
```{python eval = FALSE}
# Calculate each block's share of its TAZ's trips
#  For each block with a propensity sum...
#   - get the sum
#   - grab the block data associated with the TAZ
#   - and modify the data by dividing the block propensities by the TAZ total
for taz in taz_prop_hh.block_id.labels:
    total_prop = taz_prop_hh.take(block_id=taz).data[0]
    crit = {"block_id": {"TAZ": taz}}
    block_prop_hh.put(
        block_prop_hh.take(**crit).data/total_prop,
        **crit)
    
# Multiply the block share of propensity by the activity-based normalized
#  propensities. In this way, each block's activity-specific cell contains a
#  number defining it's share of total TAZ productions.
crit = dict([(x.name, list(x.labels)) for x in hh_array.axes 
             if x.name in hh_dims])
for p in HB_PURPS:
    purp_chunk = block_tg.take(Purpose=p, End="P", **crit)
    block_tg.put(
        purp_chunk.data *
        lba.broadcast1dByAxis(purp_chunk, "block_id", block_prop_hh.data).data,
        Purpose=p, End = "P", **crit
        )

```

## STEP 5

###
```{python eval = FALSE}
# Multiply TAZ-level trip estimates by block-level, activity-specific
#  propensities

problems = {}
for wz in window_zones:
    # Get trip total for each zone for each purpose
    taz_trips_by_purp = taz_tg.take(
        TAZ=wz, Purpose=HB_PURPS, End="P").sum(["Purpose"])
    
    # Multiply trips by purpose across relevant block features
   
    for p in HB_PURPS:
        # Trips
        trips = taz_trips_by_purp.take(Purpose=p).data[0]
        
        # Ensure the window zone is in the block propensity file
        if np.any(block_tg.block_id.labels.get_level_values("TAZ") == wz):        
            # Apply
            crit = {"Purpose": p, "End": "P",
                    "block_id": {"TAZ": wz}}
            block_tg.put(
                block_tg.take(**crit).data * trips,
                **crit)    
        else:
            prob_dict = problems.get(wz, {})
            prob_dict[p] = trips
            problems[wz] = prob_dict

#%% QUALITY CHECK
check_z = taz_tg.take(TAZ=window_zones).sum(["Purpose", "End"])
check_b = block_tg.sum(["Purpose", "End"])
for p in PURPOSES:
    for e in ["P", "A"]:
        z = np.round(check_z.take(Purpose=p, End=e).data[0], 2)
        b = np.round(check_b.take(Purpose=p, End=e).data[0], 2)
        print(p, e, z, b, b-z)
        
print("TAZs with no block data:\n", problems)

#%% ATTRACTION-END STEP 1 - ACTIVITY-BASED TRIP PROPENSITY

# Apply trip propensities by destination activity type to each block.
#  This is done by multiplying purpose-specific propensity rates by
#  the activity types in non-home activity data frame (`nh_df`)

# Since the ultimate application is to tabulate all trip attractions simply
#  as 'non-home' activities ('-' is the axis label for activity dimensions),
#  this work can be done quickly in a data frame to create block trip
#  propensity vectors that can be converted to a labeled array for subsquent
#  steps.

# Make a data frame of attraction-end propensities
a_prop_df = pd.DataFrame(ATTR_PROP, index=ATTR_ACTIVITIES)

# Join propensities to block-level data
nh_df_prop = nh_df.merge(a_prop_df, how="inner", left_on="GenSector", 
                         right_index=True)

# Multiply the activities by propensities
# Ensure each block activity has the BASE_PROP propensity at a minimum
for p in PURPOSES:
    props = ATTR_PROP[p]
    nh_df_prop[p] = (nh_df_prop[p] * nh_df_prop["tot_emp"]) + BASE_PROP
    
    
# Melt this data frame for conversion to an LbArray
nh_melted = nh_df_prop.melt(
    ["block_id", "ID"], PURPOSES, "Purpose", "Prop").groupby(
        ["block_id", "ID", "Purpose"]).sum().reset_index()

# Create the non-home array and add the TAZ ID to the block dimension, as
#  with the `hh_array` above.
# Merge to ensure all the blocks are there
nh_melted = wb_df.merge(nh_melted, how="left", left_on="GEOID10", 
                        right_on="block_id")
nh_melted.Purpose.fillna("HBW", inplace=True)
nh_melted.Prop.fillna(BASE_PROP, inplace=True)
nh_melted["block_id"] = nh_melted["GEOID10"]
nh_melted = nh_melted.groupby(["block_id", "Purpose"]).sum().reset_index()

nh_array = lba.dfToLabeledArray(nh_melted.sort_values(by="block_id"), 
                                ["block_id", "Purpose"], "Prop",
                                fill_value=BASE_PROP)
nh_array.block_id.addLevel(
    wb_df[["GEOID10", "TAZ"]], left_on="index", right_on="GEOID10")
nh_array.block_id.levels = ["block_id", "TAZ"]

#%% ATTRACTON-END: STEP 2 - TOTAL BLOCK TRIP PROPENSITY

# Summarize each block's total trip propensity using the .sum method.
block_prop_nh = nh_array.sum(["block_id", "Purpose"])

# Dissolve the block-level sums based on TAZ ID to get each zone's total
#  propensity
taz_prop_nh = nh_array.dissolve("block_id", "TAZ", np.sum).sum(
    ["block_id", "Purpose"])

#%% ATTRACTION-END: STEP 3 - NORMALIZE ACTIVITY-BASED PROPENSITIES

# There are no activity-specific propensities needed. The focus here is on
#  each block's share of the TAZ propensity by purpose. For correspondance
#  to the production-end methodology, we can just push values of 1.0 to the
#  non-home sections of the `block_tg` array
crit = dict([(x.name, "-") for x in block_tg.axes 
             if x.name in hh_dims])

# Apply to attractions
block_tg.put(1.0, End="A", **crit)

# Also apply to NHB productions
block_tg.put(1.0, Purpose="NHB", End="P", **crit)

#%% ATTRACTION-END: STEP 4 - BLOCK SHARE OF TAZ TRIP PROPENSITY

# Calculate each block's share of its TAZ's trips
#  Iterate over purposes since block propensity varies by purpose
for p in PURPOSES:
    #  For each block with a propensity sum...
    #   - get the sum
    #   - grab the block data associated with the TAZ
    #   - and modify the data by dividing the block propensities by the TAZ total
    for taz in taz_prop_nh.block_id.labels:
        total_prop = taz_prop_nh.take(block_id=taz, Purpose=p, squeeze=True).data
        crit = {"block_id": {"TAZ": taz}, "Purpose": p}
        block_prop_nh.put(
            block_prop_nh.take(**crit).data/total_prop,
            **crit)
    
    # Multiply the block share of propensity by the activity-based normalized
    #  propensities. In this way, each block's activity-specific cell contains a
    #  number defining it's share of total TAZ productions.
    crit = dict([(x.name, "-") for x in block_tg.axes 
             if x.name in hh_dims])
    purp_chunk = block_tg.take(Purpose=p, End="A", **crit)
    prop_vector = block_prop_nh.take(Purpose=p).data
    block_tg.put(
        purp_chunk.data *
        lba.broadcast1dByAxis(purp_chunk, "block_id", prop_vector).data,
        Purpose=p, End="A", **crit)
    
    if p == "NHB":
        # Do the same thing but on the production end
        purp_chunk = block_tg.take(Purpose=p, End="P", **crit)
        block_tg.put(
            purp_chunk.data *
            lba.broadcast1dByAxis(purp_chunk, "block_id", prop_vector).data,
            Purpose=p, End="P", **crit)

#%%Check
c=block_tg.take(block_id={"TAZ": 1013}, End="A", HHSize="-", Income="-",
              Workers="-", VehOwn="-", squeeze=True)

#%% ATTRACTION-END: STEP 5 - ESTIMATE DETAILED TRIPS BY BLOCK AND ACTIVITY

# Multiply TAZ-level trip estimates by block-level, activity-specific
#  propensities

problems = {}
for wz in window_zones:
    # Get trip total for each zone for each purpose
    taz_trips_by_purp = taz_tg.take(
        TAZ=wz, End="A").sum(["Purpose"])
    
    # Multiply trips by purpose across relevant block features
   
    for p in PURPOSES:
        # Trips
        trips = taz_trips_by_purp.take(Purpose=p).data[0]
        
        # Ensure the window zone is in the block propensity file
        if np.any(block_tg.block_id.labels.get_level_values("TAZ") == wz):        
            # Apply
            crit = {"Purpose": p, "End": "A",
                    "block_id": {"TAZ": wz}}
            block_tg.put(
                block_tg.take(**crit).data * trips,
                **crit)    
            
            # Also do NHB Ps
            if p == "NHB":
                crit["End"] = "P"
                block_tg.put(
                    block_tg.take(**crit).data * trips,
                    **crit)    
        else:
            prob_dict = problems.get(wz, {})
            prob_dict[p] = trips
            problems[wz] = prob_dict

#%% QUALITY CHECK
check_z = taz_tg.take(TAZ=window_zones).sum(["Purpose", "End"])
check_b = block_tg.sum(["Purpose", "End"])
for p in PURPOSES:
    for e in ["P", "A"]:
        z = np.round(check_z.take(Purpose=p, End=e).data[0], 2)
        b = np.round(check_b.take(Purpose=p, End=e).data[0], 2)
        print(p, e, z, b, b-z)

print("TAZs with no block data:\n", problems)
```